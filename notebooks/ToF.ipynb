{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution Approach\n",
    "Interferometry tracks the ToF, giving us an intensity distribution over time. Assuming the refractive indices are similar across the entire tissue structure/body, photon total path ($\\sum_{i=1}^{T}L_i$; with T being the number of tissue layers) can be a proxy for time. (If the refractive indices are different, we need to calculate the speed of light in each tissue layer/medium separately and then calculate the actual ToF for each photon. Although that approach is tractable in our setup, it's simpler to assume the speed of light remains constant for now.) So, the simulation plots we are interested in are Intensity($<G, A>$) vs. Photon total path($\\sum_{i=1}^{T}L_i$)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from inverse_modelling_tfo.tools.name_decoder import decode_extended_filename\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Pre-calculated intensity using the regular formula (inner product)\n",
    "INTENSITY_DATA_PATH = Path('../data/s_based_intensity_low_conc2.pkl')\n",
    "\n",
    "intensity_data = pd.read_pickle(INTENSITY_DATA_PATH)\n",
    "RAW_SIM_DATA_PATH = '/home/rraiyan/simulations/tfo_sim/data/raw_dan_iccps_equispace_detector/fa_1_wv_1_sa_0.1_ns_1_ms_2_ut_5.pkl'\n",
    "raw_sim_data = pd.read_pickle(RAW_SIM_DATA_PATH)\n",
    "maternal_wall_thickness, uterus_thickness, wave_int = decode_extended_filename(RAW_SIM_DATA_PATH)\n",
    "intensity_data = intensity_data[(intensity_data['Maternal Wall Thickness'] == maternal_wall_thickness) & (intensity_data['Wave Int'] == wave_int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0.11, 0.125, 0.14, 0.15500000000000003, 0.17])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intensity_data.groupby('Fetal Hb Concentration').groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inverse_modelling_tfo.tools.s_based_intensity_datagen import MU_MAP_BASE1, MU_MAP_BASE2, get_mu_a\n",
    "# Create SDD column!\n",
    "raw_sim_data['SDD'] = raw_sim_data['X'] - 100\n",
    "raw_sim_data['Total Path'] = raw_sim_data['L1 ppath'] + raw_sim_data['L2 ppath'] + raw_sim_data['L3 ppath'] + raw_sim_data['L4 ppath']\n",
    "raw_sim_data['ToF'] = 1/raw_sim_data['Total Path']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "644580e4434948b4a948ab17800a90e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=15, description='sdd_index', max=19), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_L_distribution(sdd_index)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sdd = raw_sim_data['SDD'].unique()\n",
    "\n",
    "def plot_L_distribution(sdd_index):\n",
    "    SDD = all_sdd[sdd_index]\n",
    "    plt.figure()\n",
    "    plt.hist(raw_sim_data[raw_sim_data['SDD'] == SDD][\"Total Path\"], bins=100)\n",
    "    plt.xlabel(\"Total Path (mm)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "\n",
    "sddSlider = widgets.IntSlider(15, min=0, max=19, step=1)\n",
    "interact(plot_L_distribution, sdd_index=sddSlider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_column(df, column, bins):\n",
    "    \"\"\"Quantizes a specific column in a Pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The DataFrame to quantize.\n",
    "        column (str): The name of the column to quantize.\n",
    "        bins (int): The number of bins to use for quantization.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The quantized DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the values of the column to quantize.\n",
    "    column_values = df[column].values\n",
    "\n",
    "    # Calculate the quantiles of the column values.\n",
    "    quantiles = np.linspace(df[column].min(), df[column].max(), bins + 1, endpoint=True)\n",
    "\n",
    "    # Quantize the column values.\n",
    "    quantized_values = np.digitize(column_values, quantiles)\n",
    "\n",
    "    # Add the quantized values to the DataFrame.\n",
    "    df[column] = quantized_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24847cce1d4842869603cfc0129af93c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=4.0, description='c', max=15.0), IntSlider(value=3, description='sdd_i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_distribution(c: float, sdd_index: int)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mu Map\n",
    "MATERNAL_Hb = 12.\n",
    "MATERNAL_SAT = 0.9\n",
    "FETAL_SAT = 0.225\n",
    "FETAL_Hb = 0.11\n",
    "\n",
    "DIGITIZATION_BIN_COUNT = 200\n",
    "\n",
    "modified_mu_map = MU_MAP_BASE1.copy() if wave_int == 1 else MU_MAP_BASE2\n",
    "modified_mu_map[1] = get_mu_a(MATERNAL_SAT, MATERNAL_Hb, wave_int)\n",
    "epsilon = get_mu_a(FETAL_SAT, FETAL_Hb, wave_int) / FETAL_Hb\n",
    "all_sdd = raw_sim_data['SDD'].unique()\n",
    "\n",
    "def plot_distribution(c: float, sdd_index: int):\n",
    "    SDD = all_sdd[sdd_index]\n",
    "    filtered_photon_data = raw_sim_data[raw_sim_data['SDD'] == SDD].copy()\n",
    "    G = filtered_photon_data[['L1 ppath', 'L2 ppath', 'L3 ppath']].to_numpy()\n",
    "    for i in range(1, 4):\n",
    "        G[:, i - 1] = np.exp(-modified_mu_map[i] * G[:, i - 1])\n",
    "    G = np.prod(G, axis=1)\n",
    "    L = filtered_photon_data['L4 ppath'].to_numpy()\n",
    "    transformed_L = np.exp(- epsilon * c * L)\n",
    "    I = G * transformed_L\n",
    "    filtered_photon_data[\"Intensity\"] = I\n",
    "    filtered_photon_data[\"G\"] = G\n",
    "    filtered_photon_data[\"A\"] = transformed_L\n",
    "    # bins = np.linspace(0, stop=np.max(I), endpoint=True, num=DIGITIZATION_BIN_COUNT)\n",
    "    # intensity_v_L = filtered_photon_data.groupby(\"Total Path\")[\"Intensity\"].sum()\n",
    "    quantize_column(filtered_photon_data, \"ToF\", 70)\n",
    "    intensity_v_L = filtered_photon_data.groupby(\"ToF\")[\"Intensity\"].sum()\n",
    "    G_v_L = filtered_photon_data.groupby(\"ToF\")[\"G\"].sum()\n",
    "    A_v_L = filtered_photon_data.groupby(\"ToF\")[\"A\"].sum()\n",
    "    plt.figure(figsize=(16,8))\n",
    "    # plt.plot(G_v_L * A_v_L / np.sum(G_v_L * A_v_L), label=r'$A \\times G$')\n",
    "    # \n",
    "    plt.plot(intensity_v_L/np.sum(intensity_v_L), label='Intensity')\n",
    "    plt.plot(G_v_L/ np.sum(G_v_L), label='G Component')\n",
    "    plt.plot(A_v_L/ np.sum(A_v_L), label='A Component')\n",
    "    \n",
    "    # plt.plot(np.log(intensity_v_L), label='Intensity')\n",
    "    # plt.plot(np.log(G_v_L), label='G Component')\n",
    "    # plt.plot(np.log(A_v_L), label='A Component')\n",
    "    # plt.plot(np.log(intensity_v_L) - np.log(G_v_L) - np.log(A_v_L), label='Difference')\n",
    "    # plt.plot(np.arccos(intensity_v_L/ G_v_L / A_v_L), label='Theta')\n",
    "    # plt.plot(intensity_v_L/ G_v_L / A_v_L, label='cos(Theta)')\n",
    "    \n",
    "    \n",
    "    plt.title(\"Intensity v. Total Path Length\\n(Area Normalized for plotting ease)\")    \n",
    "    plt.xlabel(\"ToF(speed of light/mm)\")\n",
    "    plt.ylabel(\"Intensity\")\n",
    "    # plt.ylim([0, 0.1])\n",
    "    # plt.yscale('log')\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "cSlider = widgets.FloatSlider(4., min=0, max=15, step=0.1)\n",
    "sddSlider = widgets.IntSlider(3, min=0, max=19, step=1)\n",
    "interact(plot_distribution, c=cSlider, sdd_index=sddSlider)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remark__: There are a bunch of things going on here\n",
    "1. When c=0, I becomes the G component. This is obvious from the equations. IF the power in the exponent for the A component goes to 0, all elements in the A component become 1. As a result I equals G. $I = G \\times A = G$. For this very specific case, (0 absorption), A vs. ToF curve mimics both I and G vs. ToF. A curves gives us the photon count at each ToF bin.\n",
    "2. The I vs. ToF distribution *cannot* be reconstrcuted by multiplying the A vs. ToF and G vs. ToF distribution together. This also makes sense from the equation. In the intensity case, you multiply then sum the photons at that ToF. In the later case, you sum first to get A and G individually, and then multiply. The order of the operation matters. This should not usually be the same!\n",
    "3. All the distribution curves look Gaussian with a small positive Skewness(leaning a bit to the left)\n",
    "4. An interesting phenomena happens when you increase c or SDD. In both cases, the mean shifts to the right, the scale decreases(Which ofcourse it does. In both conditions we receive photons with lower intensities) and the variance increases(i.e., the curves get fatter, I am guessing this corresponds to an increase in variance)\n",
    "5. These nice smooth distribution curves only appeared after I binned the ToF column. Without the binning/digitizing, the distributions do not resemble any recognizable shape. Also, the kurtosis becomes more prominent when I increase the bincount.\n",
    "6. Each individual ToF point can be broken up in the same way as the [Vector_Aprroach](/notebooks/vector_approach.ipynb)! Giving rise to similar representations at each individual point. This can similarly be broken up into $|A||G|cos(\\theta )$ with a photon count at the beginning corresponding to that specific ToF.(Again photons different combinations of L1, L2, ...LN can add up to the same sum, leading to the same ToF. It's very difficult to relate ToF distribution to individual medium photon path distribution)\n",
    "7. Plotting the cosine at each ToF bin shows us some interesting properties! For example, the cosine shifts from 0 to 1 as ToF goes from 0 to max ToF. But this change is not gradual. Rather there is a sudden, and very sharp shift. (It looks a lot like a shifted sigmoid). Also, the cosine does not seem rely on c. But the point of this sudden shift depends on SDD. Let's call it the 'critical point'. It shifts right as we increase SDD. I have no idea how to explain this behaviour. (So for changing c, the values change ever so slightly, but its not at all significant and you can barely notice anything. This also serves to prove that there is no bug in the code, that the cosine the calculations for c does indeed change with c but the values do not)\n",
    "8. The cosine curve has sharp changes but the log(cos(theta)) has a very smooth change. Which I guess makes sense. (Is also probably easier to work with!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10., 14., 19., 28., 23., 32., 46., 50., 37., 41., 55., 64., 59.,\n",
       "       68., 91., 86., 73., 77., 82., 95.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_sim_data['SDD'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cybercat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
